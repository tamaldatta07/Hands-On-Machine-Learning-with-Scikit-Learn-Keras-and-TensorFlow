{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c01f3e1",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "\n",
    "Missing data is the absence of values in certain observations of a variable. Missing data is an unavoidable problem in most data sources and may have a significant impact on the conclusions that we derived from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23fd7e2",
   "metadata": {},
   "source": [
    "`Why is the data missing?`\n",
    "\n",
    "The source of missing data can vary. These are just some examples:\n",
    "\n",
    "* The value was forgotten, lost, or not stored properly.\n",
    "\n",
    "* The value does not exist.\n",
    "\n",
    "* The value can't be known or identified.\n",
    "\n",
    "To give real-life examples, a person may choose not to complete all fields in a form if they are not mandatory. That would introduce missing data. Sometimes people do not want to disclose some information, for example, income, or they do not know the answers to the questions being asked.\n",
    "\n",
    "Sometimes the value for a certain variable does not exist. For example, in the variable \"total debt as percentage of total income\" (very common in financial data), if the person has no income, then the total percentage of 0 does not exist, and therefore it will be a missing value.\n",
    "\n",
    "It's important to understand why data is missing, in other words, the mechanism of missing data. We may process the missing information differently depending on this mechanism. Furthermore, identifying the source of missing data allows us to take steps to regulate that source and reduce the amount of missing data as data collection progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a633f722",
   "metadata": {},
   "source": [
    "### Missing data mechanisms\n",
    "\n",
    "There are 3 mechanisms that lead to missing data. Two of them involve missing data randomly and the third one involves a systematic loss of data.\n",
    "\n",
    "`Missing Completely at Random, MCAR:`\n",
    "If the likelihood of a value being missing is the same for all observations, the variable is missing completely at random (MCAR). The data points that are missing are a random subset of the observations.\n",
    "\n",
    "If data is MCAR, then disregarding observations with missing data would not bias the inferences made.\n",
    "\n",
    "`Missing at Random, MAR:`\n",
    "If the probability of an observation being missing depends on available information (i.e., other variables), then the observation is missing at random (MAR). There is a relationship between the likelihood of a value being missing and the observed data.\n",
    "\n",
    "For example, if men are more likely to disclose their weight than women, weight is MAR. The weight information will be missing at random for the men and women who did not disclose their weight, but as men are more prone to disclose it, there will be more missing values for women than for men.\n",
    "\n",
    "In this example, missing data points are no longer a random subset of the total observations.\n",
    "\n",
    "If we decide to proceed with the variable with missing values (in this case weight), we might want to include the variable gender to control the bias in weight for the missing observations.\n",
    "\n",
    "`Missing Not at Random, MNAR:`\n",
    "If there is a mechanism or a reason why data is missing, then that data is missing not at random (MNAR). For example, if people failed to fill out a depression survey because of their depression, those data points would be missing not at random. The missing data occurs due to the depression.\n",
    "\n",
    "Depending on the mechanism by which missing values occur, we may choose different missing data imputation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169f4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To display all columns in the dataset.\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e578643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375    B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500   C22        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500   C22        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500   C22        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500   C22        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load the titanic dataset.\n",
    "data = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Let's inspect the first 5 rows.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed659da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass          0\n",
       "survived        0\n",
       "name            0\n",
       "sex             0\n",
       "age           263\n",
       "sibsp           0\n",
       "parch           0\n",
       "ticket          0\n",
       "fare            1\n",
       "cabin        1014\n",
       "embarked        2\n",
       "boat          823\n",
       "body         1188\n",
       "home.dest     564\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the isnull() method plus the sum() method:\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e584e",
   "metadata": {},
   "source": [
    "There are 263 missing values for Age, 1014 for Cabin and 2 for Embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4266fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass       0.000000\n",
       "survived     0.000000\n",
       "name         0.000000\n",
       "sex          0.000000\n",
       "age          0.200917\n",
       "sibsp        0.000000\n",
       "parch        0.000000\n",
       "ticket       0.000000\n",
       "fare         0.000764\n",
       "cabin        0.774637\n",
       "embarked     0.001528\n",
       "boat         0.628724\n",
       "body         0.907563\n",
       "home.dest    0.430863\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to obtain the fraction of missing values:\n",
    "\n",
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2fc50d",
   "metadata": {},
   "source": [
    "In the variables Age there is 20% of data missing.\n",
    "\n",
    "There is 77 percent of data missing in the variable Cabin, in which the passenger was traveling.\n",
    "\n",
    "There is 0.2 percent of data missing in the field Embarked (the port from which the passenger boarded the Titanic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a70fb7",
   "metadata": {},
   "source": [
    "### Missing data Not At Random (MNAR)\n",
    "The missing values of the variables `age` and `cabin`, were introduced systematically. For many of those who did not survive, their age or their cabin remains unknown. The people who survived could have been otherwise asked for that information.\n",
    "\n",
    "If data is MNAR, we could expect a greater number of missing values for people who did not survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a10b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a binary variable that indicates if the value of cabin is missing.\n",
    "\n",
    "data['cabin_null'] = np.where(data['cabin'].isnull(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ca1129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    0.873918\n",
       "1    0.614000\n",
       "Name: cabin_null, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's evaluate the percentage of missing values in\n",
    "# cabin for the people who survived vs the non-survivors.\n",
    "\n",
    "# The variable Survived takes the value 1 if the passenger\n",
    "# survived, or 0 otherwise.\n",
    "\n",
    "# Group data by Survived vs Non-Survived\n",
    "# and find the percentage of NaN for Cabin.\n",
    "\n",
    "data.groupby(['survived'])['cabin_null'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f301738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    0.873918\n",
       "1    0.614000\n",
       "Name: cabin, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way of doing the above, with less lines of code\n",
    "data['cabin'].isnull().groupby(data['survived']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8b88d",
   "metadata": {},
   "source": [
    "The percentage of missing values is higher for those who did not survive (87% vs 60% for survivors). This finding could support our hypothesis that the data is missing because after people died, the information could not be retrieved.\n",
    "\n",
    "**Note:** `to truly understand whether the data is missing not at random, we would need to get extremely familiar with the way data was collected. Analysing datasets, can only point us in the right direction or help us make assumptions.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c69693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    0.234858\n",
       "1    0.146000\n",
       "Name: age_null, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do the same for the variable age:\n",
    "\n",
    "data['age_null'] = np.where(data['age'].isnull(), 1, 0)\n",
    "data.groupby(['survived'])['age_null'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11d3c77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    0.234858\n",
       "1    0.146000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'].isnull().groupby(data['survived']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb10cc",
   "metadata": {},
   "source": [
    "So, more missing data points for the people who did not survive. The analysis therefore suggests that there was a systematic loss of data: people who did not survive had more missing information. Presumably, the method chosen to gather the information contributes to the generation of this missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c48e73",
   "metadata": {},
   "source": [
    "### Missing data Completely At Random (MCAR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dcfad71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>cabin_null</th>\n",
       "      <th>age_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cincinatti, OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  survived                                       name     sex  \\\n",
       "168       1         1                        Icard, Miss. Amelie  female   \n",
       "284       1         1  Stone, Mrs. George Nelson (Martha Evelyn)  female   \n",
       "\n",
       "      age  sibsp  parch  ticket  fare cabin embarked boat  body  \\\n",
       "168  38.0      0      0  113572  80.0   B28      NaN    6   NaN   \n",
       "284  62.0      0      0  113572  80.0   B28      NaN    6   NaN   \n",
       "\n",
       "          home.dest  cabin_null  age_null  \n",
       "168             NaN           0         0  \n",
       "284  Cincinatti, OH           0         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  In the titanic dataset, there are also missing values for the variable Embarked.\n",
    "data[data['embarked'].isnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89549701",
   "metadata": {},
   "source": [
    "These 2 women were traveling together. Miss Icard was the maid of Mrs. Stone.\n",
    "\n",
    "A priori, there does not seem to be an indication that the missing information in the variable \"embarked\" is dependent on any other variable, and the fact that these women survived means that they could have been asked for this information.\n",
    "\n",
    "It is very likely the values were lost at the time of building the dataset.\n",
    "\n",
    "If these values are MCAR, the likelihood of data missing for these two women is the same as the likelihood of data missing for any other person on the Titanic. Of course, this will be hard, if possible at all, to prove."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211b290",
   "metadata": {},
   "source": [
    "### Missing data at Random (MAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e813c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employment</th>\n",
       "      <th>time_employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teacher</td>\n",
       "      <td>&lt;=5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>&lt;=5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>&lt;=5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other</td>\n",
       "      <td>&lt;=5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bus driver</td>\n",
       "      <td>&gt;5 years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     employment time_employed\n",
       "0       Teacher     <=5 years\n",
       "1    Accountant     <=5 years\n",
       "2  Statistician     <=5 years\n",
       "3         Other     <=5 years\n",
       "4    Bus driver      >5 years"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load the dataset with just the 2 variables.\n",
    "\n",
    "data = pd.read_csv('loan.csv', usecols=['employment', 'time_employed'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffc608ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment       0.0611\n",
       "time_employed    0.0529\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the percentage of missing data.\n",
    "\n",
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b00a7ab",
   "metadata": {},
   "source": [
    "Both variables have roughly the same percentage of missing observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e8eddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of employments: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Teacher', 'Accountant', 'Statistician', 'Other', 'Bus driver',\n",
       "       'Secretary', 'Software developer', 'Nurse', 'Taxi driver', nan,\n",
       "       'Civil Servant', 'Dentist'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lLt's insptect the different employment types.\n",
    "\n",
    "# Number of different employments.\n",
    "print('Number of employments: {}'.format(\n",
    "    len(data['employment'].unique())))\n",
    "\n",
    "# Examples of employments.\n",
    "data['employment'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b66ec00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=5 years', '>5 years', nan], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's inspect the variable time employed.\n",
    "\n",
    "data['time_employed'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02937457",
   "metadata": {},
   "source": [
    "The customer can't enter a value for employment time if they are not employed. They could be students, retired, self-employed, or something else. Note how these 2 variables are related to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c25afeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005325380764724678"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calculate the proportion of missing data in time_employed variable when\n",
    "# customers declared employment.\n",
    "\n",
    "# Customers who declared employment\n",
    "t = data[~data['employment'].isnull()]\n",
    "\n",
    "# Percentage of missing data in time employed\n",
    "t['time_employed'].isnull().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c45ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576104746317512"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do the same for those borrowers who did not \n",
    "# report employment.\n",
    "\n",
    "# Customers who did not declare employment.\n",
    "t = data[data['employment'].isnull()]\n",
    "\n",
    "# Percentage of missing data in time employed.\n",
    "t['time_employed'].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea032be",
   "metadata": {},
   "source": [
    "The number of borrowers who have reported occupation and have missing values in time_employed is minimal. Customers who did not report an occupation, on the other hand, mostly show missing values in the time_employed variable.\n",
    "\n",
    "This further supports the hypothesis that the missing values in employment are related to the missing values in time_employed.\n",
    "\n",
    "This is an example of MAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236bc050",
   "metadata": {},
   "source": [
    "# Cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe680c",
   "metadata": {},
   "source": [
    "The values of a categorical variable are selected from a group of categories, also called labels. For example, in the variable gender the categories are male and female, whereas in the variable city the labels could be London, Manchester, Brighton, and so on.\n",
    "\n",
    "Categorical variables can contain different numbers of categories. The variable \"gender\" contains only 2 labels, but a variable like \"city\" or \"postcode\" can contain a huge number of labels.\n",
    "\n",
    "The number of different labels is known as cardinality. A high number of labels within a variable is known as high cardinality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4360efd9",
   "metadata": {},
   "source": [
    "### Is high cardinality a problem?\n",
    "\n",
    "High cardinality poses the following challenges:\n",
    "\n",
    "* Variables with too many labels tend to dominate those with only a few labels, particularly in decision tree-based algorithms.\n",
    "\n",
    "* High cardinality may introduce noise.\n",
    "\n",
    "* Some of the labels may only be present in the training data set and not in the test set, so machine learning algorithms may     over-fit to the training set.\n",
    "\n",
    "* Some labels may appear only in the test set, leaving the machine learning algorithms unable to perform a calculation over the   new (unseen) observation.\n",
    "\n",
    "**Algorithms based on decision trees can be biased towards variables with high cardinality.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53e3a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The machine learning models.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# To evaluate the models.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# To separate data into train and test.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a578b583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375    B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500   C22        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500   C22        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500   C22        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500   C22        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('titanic.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdebdb2",
   "metadata": {},
   "source": [
    "The categorical variables are Name, Sex, Ticket, Cabin and Embarked.\n",
    "\n",
    "**Note:** `Ticket and Cabin contain both letters and numbers, so they could be treated as Mixed Variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8841cc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories in the variable Name: 1307\n",
      "Number of categories in the variable Gender: 2\n",
      "Number of categories in the variable Ticket: 929\n",
      "Number of categories in the variable Cabin: 182\n",
      "Number of categories in the variable Embarked: 4\n",
      "Total number of passengers in the Titanic: 1309\n"
     ]
    }
   ],
   "source": [
    "# Inspect the cardinality: the number of different labels.\n",
    "\n",
    "print('Number of categories in the variable Name: {}'.format(\n",
    "    len(data.name.unique())))\n",
    "\n",
    "print('Number of categories in the variable Gender: {}'.format(\n",
    "    len(data.sex.unique())))\n",
    "\n",
    "print('Number of categories in the variable Ticket: {}'.format(\n",
    "    len(data.ticket.unique())))\n",
    "\n",
    "print('Number of categories in the variable Cabin: {}'.format(\n",
    "    len(data.cabin.unique())))\n",
    "\n",
    "print('Number of categories in the variable Embarked: {}'.format(\n",
    "    len(data.embarked.unique())))\n",
    "\n",
    "print('Total number of passengers in the Titanic: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9740aef",
   "metadata": {},
   "source": [
    "While the variable Sex contains only 2 categories and the variable Embarked 4 (low cardinality), the variables Ticket, Name, and Cabin, as expected, contain a huge number of different labels (high cardinality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a46002e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B5', 'C22', 'E12', 'D7', 'A36', 'C101', nan, 'C62', 'B35', 'A23',\n",
       "       'B58', 'D15', 'C6', 'D35', 'C148', 'C97', 'B49', 'C99', 'C52', 'T',\n",
       "       'A31', 'C7', 'C103', 'D22', 'E33', 'A21', 'B10', 'B4', 'E40',\n",
       "       'B38', 'E24', 'B51', 'B96', 'C46', 'E31', 'E8', 'B61', 'B77', 'A9',\n",
       "       'C89', 'A14', 'E58', 'E49', 'E52', 'E45', 'B22', 'B26', 'C85',\n",
       "       'E17', 'B71', 'B20', 'A34', 'C86', 'A16', 'A20', 'A18', 'C54',\n",
       "       'C45', 'D20', 'A29', 'C95', 'E25', 'C111', 'C23', 'E36', 'D34',\n",
       "       'D40', 'B39', 'B41', 'B102', 'C123', 'E63', 'C130', 'B86', 'C92',\n",
       "       'A5', 'C51', 'B42', 'C91', 'C125', 'D10', 'B82', 'E50', 'D33',\n",
       "       'C83', 'B94', 'D49', 'D45', 'B69', 'B11', 'E46', 'C39', 'B18',\n",
       "       'D11', 'C93', 'B28', 'C49', 'B52', 'E60', 'C132', 'B37', 'D21',\n",
       "       'D19', 'C124', 'D17', 'B101', 'D28', 'D6', 'D9', 'B80', 'C106',\n",
       "       'B79', 'C47', 'D30', 'C90', 'E38', 'C78', 'C30', 'C118', 'D36',\n",
       "       'D48', 'D47', 'C105', 'B36', 'B30', 'D43', 'B24', 'C2', 'C65',\n",
       "       'B73', 'C104', 'C110', 'C50', 'B3', 'A24', 'A32', 'A11', 'A10',\n",
       "       'B57', 'C28', 'E44', 'A26', 'A6', 'A7', 'C31', 'A19', 'B45', 'E34',\n",
       "       'B78', 'B50', 'C87', 'C116', 'C55', 'D50', 'E68', 'E67', 'C126',\n",
       "       'C68', 'C70', 'C53', 'B19', 'D46', 'D37', 'D26', 'C32', 'C80',\n",
       "       'C82', 'C128', 'E39', 'D', 'F4', 'D56', 'F33', 'E101', 'E77', 'F2',\n",
       "       'D38', 'F', 'E121', 'E10', 'G6', 'F38'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cabin.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dee877",
   "metadata": {},
   "source": [
    "From the previous cell we can see that there are 148 different cabins, therefore the variable is highly cardinal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e86d8",
   "metadata": {},
   "source": [
    "**Rationale**: `the first letter indicates the deck on which the cabin was located, indicating both social class status and proximity to the Titanic's surface. Both are known to improve the probability of survival.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b441088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cabin</th>\n",
       "      <th>Cabin_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B5</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C22</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C22</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C22</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C22</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cabin Cabin_reduced\n",
       "0    B5             B\n",
       "1   C22             C\n",
       "2   C22             C\n",
       "3   C22             C\n",
       "4   C22             C"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's capture the first letter of cabin.\n",
    "\n",
    "data['Cabin_reduced'] = data['cabin'].astype(str).str[0]\n",
    "\n",
    "data[['cabin', 'Cabin_reduced']].head()\n",
    "# So the cardinality of the variable is reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eb5f297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories in the variable Cabin: 182\n",
      "Number of categories in the variable Cabin reduced: 9\n"
     ]
    }
   ],
   "source": [
    "print('Number of categories in the variable Cabin: {}'.format(\n",
    "    len(data.cabin.unique())))\n",
    "\n",
    "print('Number of categories in the variable Cabin reduced: {}'.format(\n",
    "    len(data.Cabin_reduced.unique())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab692a4d",
   "metadata": {},
   "source": [
    "Number of different labels reduced from 182 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aafb3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((916, 3), (393, 3))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's separate the data into training and testing sets.\n",
    "\n",
    "use_cols = ['cabin', 'Cabin_reduced', 'sex']\n",
    "\n",
    "# This functions is from Scikit-learn\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[use_cols], \n",
    "    data['survived'],  \n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c843a6a",
   "metadata": {},
   "source": [
    "### Uneven distribution of categories\n",
    "When a variable is highly cardinal, some categories appear only on the training set, and others only on the testing set. If present only in the training set, they may cause over-fitting. If present only on the testing set, the machine learning model will not know how to handle them, as they were not seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63e9a5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels present only in the training set:\n",
    "\n",
    "unique_to_train_set = [\n",
    "    x for x in X_train.cabin.unique() if x not in X_test.cabin.unique()\n",
    "]\n",
    "\n",
    "len(unique_to_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2e9442e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels present only in the test set.\n",
    "\n",
    "unique_to_test_set = [\n",
    "    x for x in X_test.cabin.unique() if x not in X_train.cabin.unique()\n",
    "]\n",
    "\n",
    "len(unique_to_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ac5b3",
   "metadata": {},
   "source": [
    "Variables with high cardinality have categories present either only in the training set, or only in the testing set. This will cause problems at the time of training (over-fitting) and scoring of new data.\n",
    "\n",
    "This problem can be mitigated by reducing the cardinality of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "516e0156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels present only in the training set for Cabin with reduced cardinality.\n",
    "\n",
    "unique_to_train_set = [\n",
    "    x for x in X_train['Cabin_reduced'].unique()\n",
    "    if x not in X_test['Cabin_reduced'].unique()\n",
    "]\n",
    "\n",
    "len(unique_to_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fd4a546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels present only in the test set for Cabin with reduced cardinality.\n",
    "\n",
    "unique_to_test_set = [\n",
    "    x for x in X_test['Cabin_reduced'].unique()\n",
    "    if x not in X_train['Cabin_reduced'].unique()\n",
    "]\n",
    "\n",
    "len(unique_to_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a3639f",
   "metadata": {},
   "source": [
    "By reducing the cardinality, there is now only 1 label in the training set that is not present in the test set. There is no label in the test set that is not in the training set either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea599a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: 0,\n",
       " 'E36': 1,\n",
       " 'C68': 2,\n",
       " 'E24': 3,\n",
       " 'C22': 4,\n",
       " 'D38': 5,\n",
       " 'B50': 6,\n",
       " 'A24': 7,\n",
       " 'C111': 8,\n",
       " 'F': 9,\n",
       " 'C6': 10,\n",
       " 'C87': 11,\n",
       " 'E8': 12,\n",
       " 'B45': 13,\n",
       " 'C93': 14,\n",
       " 'D28': 15,\n",
       " 'D36': 16,\n",
       " 'C125': 17,\n",
       " 'B35': 18,\n",
       " 'T': 19,\n",
       " 'B73': 20,\n",
       " 'B57': 21,\n",
       " 'A26': 22,\n",
       " 'A18': 23,\n",
       " 'B96': 24,\n",
       " 'G6': 25,\n",
       " 'C78': 26,\n",
       " 'C101': 27,\n",
       " 'D9': 28,\n",
       " 'D33': 29,\n",
       " 'C128': 30,\n",
       " 'E50': 31,\n",
       " 'B26': 32,\n",
       " 'B69': 33,\n",
       " 'E121': 34,\n",
       " 'C123': 35,\n",
       " 'B94': 36,\n",
       " 'A34': 37,\n",
       " 'D': 38,\n",
       " 'C39': 39,\n",
       " 'D43': 40,\n",
       " 'E31': 41,\n",
       " 'B5': 42,\n",
       " 'D17': 43,\n",
       " 'F33': 44,\n",
       " 'E44': 45,\n",
       " 'D7': 46,\n",
       " 'A21': 47,\n",
       " 'D34': 48,\n",
       " 'A29': 49,\n",
       " 'D35': 50,\n",
       " 'A11': 51,\n",
       " 'B51': 52,\n",
       " 'D46': 53,\n",
       " 'E60': 54,\n",
       " 'C30': 55,\n",
       " 'D26': 56,\n",
       " 'E68': 57,\n",
       " 'A9': 58,\n",
       " 'B71': 59,\n",
       " 'D37': 60,\n",
       " 'F2': 61,\n",
       " 'C55': 62,\n",
       " 'C89': 63,\n",
       " 'C124': 64,\n",
       " 'C23': 65,\n",
       " 'C126': 66,\n",
       " 'E49': 67,\n",
       " 'E46': 68,\n",
       " 'D19': 69,\n",
       " 'B58': 70,\n",
       " 'C82': 71,\n",
       " 'B52': 72,\n",
       " 'C92': 73,\n",
       " 'E45': 74,\n",
       " 'C65': 75,\n",
       " 'E25': 76,\n",
       " 'B3': 77,\n",
       " 'D40': 78,\n",
       " 'C91': 79,\n",
       " 'B102': 80,\n",
       " 'B61': 81,\n",
       " 'A20': 82,\n",
       " 'B36': 83,\n",
       " 'C7': 84,\n",
       " 'B77': 85,\n",
       " 'D20': 86,\n",
       " 'C148': 87,\n",
       " 'C105': 88,\n",
       " 'E38': 89,\n",
       " 'B86': 90,\n",
       " 'C132': 91,\n",
       " 'C86': 92,\n",
       " 'A14': 93,\n",
       " 'C54': 94,\n",
       " 'A5': 95,\n",
       " 'B49': 96,\n",
       " 'B28': 97,\n",
       " 'B24': 98,\n",
       " 'C2': 99,\n",
       " 'F4': 100,\n",
       " 'A6': 101,\n",
       " 'C83': 102,\n",
       " 'B42': 103,\n",
       " 'A36': 104,\n",
       " 'C52': 105,\n",
       " 'D56': 106,\n",
       " 'C116': 107,\n",
       " 'B19': 108,\n",
       " 'E77': 109,\n",
       " 'E101': 110,\n",
       " 'B18': 111,\n",
       " 'C95': 112,\n",
       " 'D15': 113,\n",
       " 'E33': 114,\n",
       " 'B30': 115,\n",
       " 'D21': 116,\n",
       " 'E10': 117,\n",
       " 'C130': 118,\n",
       " 'D6': 119,\n",
       " 'C51': 120,\n",
       " 'D30': 121,\n",
       " 'E67': 122,\n",
       " 'C110': 123,\n",
       " 'C103': 124,\n",
       " 'C90': 125,\n",
       " 'C118': 126,\n",
       " 'C97': 127,\n",
       " 'D47': 128,\n",
       " 'E34': 129,\n",
       " 'B4': 130,\n",
       " 'D50': 131,\n",
       " 'C62': 132,\n",
       " 'E17': 133,\n",
       " 'B41': 134,\n",
       " 'C49': 135,\n",
       " 'C85': 136,\n",
       " 'B20': 137,\n",
       " 'C28': 138,\n",
       " 'E63': 139,\n",
       " 'C99': 140,\n",
       " 'D49': 141,\n",
       " 'A10': 142,\n",
       " 'A16': 143,\n",
       " 'B37': 144,\n",
       " 'C80': 145,\n",
       " 'B78': 146}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabin_dict = {k: i for i, k in enumerate(X_train.cabin.unique(), 0)}\n",
    "cabin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57d3ebfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin_mapped</th>\n",
       "      <th>cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>E36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2</td>\n",
       "      <td>C68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>3</td>\n",
       "      <td>E24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cabin_mapped cabin\n",
       "501              0   NaN\n",
       "588              0   NaN\n",
       "402              0   NaN\n",
       "1193             0   NaN\n",
       "686              0   NaN\n",
       "971              0   NaN\n",
       "117              1   E36\n",
       "540              0   NaN\n",
       "294              2   C68\n",
       "261              3   E24"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the labels in Cabin with the dictionary\n",
    "\n",
    "X_train.loc[:, 'Cabin_mapped'] = X_train.loc[:, 'cabin'].map(cabin_dict)\n",
    "X_test.loc[:, 'Cabin_mapped'] = X_test.loc[:, 'cabin'].map(cabin_dict)\n",
    "\n",
    "X_train[['Cabin_mapped', 'cabin']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "600d8f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin_reduced</th>\n",
       "      <th>cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>E36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2</td>\n",
       "      <td>C68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>E24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cabin_reduced cabin\n",
       "501               0   NaN\n",
       "588               0   NaN\n",
       "402               0   NaN\n",
       "1193              0   NaN\n",
       "686               0   NaN\n",
       "971               0   NaN\n",
       "117               1   E36\n",
       "540               0   NaN\n",
       "294               2   C68\n",
       "261               1   E24\n",
       "587               0   NaN\n",
       "489               0   NaN\n",
       "2                 2   C22\n",
       "405               0   NaN\n",
       "1284              0   NaN\n",
       "338               0   NaN\n",
       "356               0   NaN\n",
       "985               0   NaN\n",
       "182               0   NaN\n",
       "1027              0   NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the letters in the reduced cabin variable using the same procedure.\n",
    "\n",
    "# Create replacement dictionary.\n",
    "cabin_dict = {k: i for i, k in enumerate(X_train['Cabin_reduced'].unique(), 0)}\n",
    "\n",
    "# Replace labels by numbers using dictionary.\n",
    "X_train.loc[:, 'Cabin_reduced'] = X_train.loc[:, 'Cabin_reduced'].map(\n",
    "    cabin_dict)\n",
    "X_test.loc[:, 'Cabin_reduced'] = X_test.loc[:, 'Cabin_reduced'].map(cabin_dict)\n",
    "\n",
    "X_train[['Cabin_reduced', 'cabin']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf42211",
   "metadata": {},
   "source": [
    "E36 and E24 take the same number 1, because here this process is capturing only one letter, they both start with E "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4c30466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501     1\n",
       "588     1\n",
       "402     1\n",
       "1193    0\n",
       "686     1\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-map the categorical variable Sex into numbers.\n",
    "\n",
    "X_train.loc[:, 'sex'] = X_train.loc[:, 'sex'].map({'male': 0, 'female': 1})\n",
    "X_test.loc[:, 'sex'] = X_test.loc[:, 'sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "X_train.sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9974ea4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_mapped     0\n",
       "Cabin_reduced    0\n",
       "sex              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are missing values in these variables.\n",
    "\n",
    "X_train[['Cabin_mapped', 'Cabin_reduced', 'sex']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9642c92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_mapped     41\n",
       "Cabin_reduced     0\n",
       "sex               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[['Cabin_mapped', 'Cabin_reduced', 'sex']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2344d67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the number of different categories in the encoded variables.\n",
    "\n",
    "len(X_train.Cabin_mapped.unique()), len(X_train.Cabin_reduced.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd3181",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6399711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.853790650048556\n",
      "Test set\n",
      "Random Forests roc-auc: 0.7691361097284443\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with high cardinality.\n",
    "\n",
    "# The model.\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39)\n",
    "\n",
    "# Train the model.\n",
    "rf.fit(X_train[['Cabin_mapped', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = rf.predict_proba(X_train[['Cabin_mapped', 'sex']])\n",
    "pred_test = rf.predict_proba(X_test[['Cabin_mapped', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8402673",
   "metadata": {},
   "source": [
    "The performance of the Random Forests on the training set is quite superior to its performance on the test set. This indicates that the model is over-fitting, which means that it does a great job of predicting the outcome on the dataset it was trained on, but it lacks the power to generalise the prediction to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "417ed6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8163420365403872\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8017670482827277\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with low cardinality.\n",
    "\n",
    "# The model.\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39)\n",
    "\n",
    "# Train the model.\n",
    "rf.fit(X_train[['Cabin_reduced', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = rf.predict_proba(X_train[['Cabin_reduced', 'sex']])\n",
    "pred_test = rf.predict_proba(X_test[['Cabin_reduced', 'sex']])\n",
    "\n",
    "print('Train set')\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c02b73",
   "metadata": {},
   "source": [
    "**Note** `Random Forests no longer over-fit to the training set. The model is much better at generalising the predictions (compare the ROC-AUC of this model vs the ROC-AUC of the previous model: : 0.81 vs 0.80).`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e6a4e",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d15e44a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Adaboost roc-auc: 0.8296861713101102\n",
      "Test set\n",
      "Adaboost roc-auc: 0.7604391350035948\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with high cardinality.\n",
    "\n",
    "# The model.\n",
    "ada = AdaBoostClassifier(n_estimators=200, random_state=44)\n",
    "\n",
    "# Train the model.\n",
    "ada.fit(X_train[['Cabin_mapped', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set\n",
    "pred_train = ada.predict_proba(X_train[['Cabin_mapped', 'sex']])\n",
    "pred_test = ada.predict_proba(X_test[['Cabin_mapped', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Adaboost roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Adaboost roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58e43169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Adaboost roc-auc: 0.8161256723642566\n",
      "Test set\n",
      "Adaboost roc-auc: 0.8001078480172557\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with fewer categories.\n",
    "\n",
    "# The model.\n",
    "ada = AdaBoostClassifier(n_estimators=200, random_state=44)\n",
    "\n",
    "# Train the model.\n",
    "ada.fit(X_train[['Cabin_reduced', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = ada.predict_proba(X_train[['Cabin_reduced', 'sex']])\n",
    "pred_test = ada.predict_proba(X_test[['Cabin_reduced', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Adaboost roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Adaboost roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c813a",
   "metadata": {},
   "source": [
    "Similarly, Adaboost trained with the variable with high cardinality overfits to the train set. Adaboost trained with the low cardinal variable does not overfit.\n",
    "\n",
    "In addition, trainind AdaBoost with data with less categories in Cabin, returns a) a simpler model and, b) should a different category in the test set appear, by taking just the front letter of cabin, the ML model will know how to handle it because, most likely, the value was seen during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6346d5",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b2e7d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic regression roc-auc: 0.8133909298124677\n",
      "Test set\n",
      "Logistic regression roc-auc: 0.7750815773463858\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with high cardinality.\n",
    "\n",
    "# The model.\n",
    "logit = LogisticRegression(random_state=44, solver='lbfgs')\n",
    "\n",
    "# Train the model.\n",
    "logit.fit(X_train[['Cabin_mapped', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = logit.predict_proba(X_train[['Cabin_mapped', 'sex']])\n",
    "pred_test = logit.predict_proba(X_test[['Cabin_mapped', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4397161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic regression roc-auc: 0.8123468468695123\n",
      "Test set\n",
      "Logistic regression roc-auc: 0.8008268347989602\n"
     ]
    }
   ],
   "source": [
    "# Model trained with data with fewer categories.\n",
    "\n",
    "# The model.\n",
    "logit = LogisticRegression(random_state=44, solver='lbfgs')\n",
    "\n",
    "# Train the model.\n",
    "logit.fit(X_train[['Cabin_reduced', 'sex']], y_train)\n",
    "\n",
    "# Make predictions on train and test set.\n",
    "pred_train = logit.predict_proba(X_train[['Cabin_reduced', 'sex']])\n",
    "pred_test = logit.predict_proba(X_test[['Cabin_reduced', 'sex']].fillna(0))\n",
    "\n",
    "print('Train set')\n",
    "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_train, pred_train[:,1])))\n",
    "print('Test set')\n",
    "print('Logistic regression roc-auc: {}'.format(roc_auc_score(y_test, pred_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1645e1",
   "metadata": {},
   "source": [
    "Reducing the cardinality improves the performance of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb7702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
